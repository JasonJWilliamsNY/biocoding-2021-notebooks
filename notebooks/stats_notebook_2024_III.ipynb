{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a hypothesis\n",
    "\n",
    "Now we come to what is often the main paradigm in science: hypothesis testing. \n",
    "\n",
    "[Hypothesis](https://en.wikipedia.org/wiki/Hypothesis) is a proposed explanation about some phenomenon. A hypothesis is not a guess, but is usually a reasonable argument that explains why something occurs. The way science works is by making observations, thinking about what might be causing those observations and then coming up with a reasonable hypothesis. This hypothesis now needs evidence to support it. How do we quantify this process of \"evidence support\" for a hypothesis?\n",
    "\n",
    "In hypothesis testing, we first establish something called a **Null Hypothesis**. A Null Hypothesis, referred to as $\\mathbf{H}_0$, is the standard default hypothesis about a phenomenon or can be the prevailing hypothesis about the phenomenon. For example, let us say we are developing a drug for Malaria. The null hypothesis here would be that the drug doesn't work. That is the default assumption, the job of science is to \"disprove\" the null hypothesis in the favor of the scientists' hypothesis (called the **alternative hypothesis**, referred to as $\\mathbf{H}_1$). This way, the process of showing that the drug works is reduced to disproving that it doesn't work! \n",
    "\n",
    "(NOTE: It is not exactly correct to use \"disprove\" since things cannot usually be proven or disproven outside of mathematics. Evidence can only support or oppose hypotheses.)\n",
    "\n",
    "#### Questions!\n",
    "\n",
    "**Q**: Why can we not say prove or disprove? Does that make mathematics different from observational science?\n",
    "\n",
    "**Q**: Why do we care about gathering evidence against a null hypothesis rather than directly evidence supporting the alternative? Think of trying to prove that all flamingoes are pink. Does it help to see more and more pink flamingoes or look for a white one?\n",
    "\n",
    "### Thinking about error\n",
    "\n",
    "Let us say we have a Null Hypothesis that tortoises are as fast as rabbits (why should we think otherwise?). We go to the woods and make observations and think that maybe that isn't true. Maybe rabbits are faster. So we come up with our alternative hypothesis that rabbits are faster.\n",
    "\n",
    "We do some statistical magic and we can reach one of two possible outcomes. Either we reject the null hypothesis (in favor of the alternative) or we fail to reject the null hypothesis (in which case we stick with it for now). Out in the real world, the null hypothesis is either true or false, irrespective of what kind of statistics we do. Therefore, we can summarize the possible outsomes in the form of a 2 by 2 table\n",
    "\n",
    "||Null is True|Null is False|\n",
    "|:--:|:--:|:--:|\n",
    "|We rejected the Null|ERROR|AWESOME!!|\n",
    "|We failed to reject the Null|AWESOME!!|ERROR|\n",
    "\n",
    "The two different errors are often called Type 1 and Type 2 Errors. Look at the meme below and try to figure out which of the errors is type 1 and which is type 2!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/type-i-and-type-ii-errors.jpg)\n",
    "\n",
    "\n",
    "## How exactly can we do this?\n",
    "\n",
    "In our example, what we want to do is to compare the population distribution of the rabbit speeds to the population distribution of the tortoise speeds. How do we do this? We might need to make some assumptions. What if we assume that both of the animal speeds follow a Normal distribution? We can then do some quantitative comparisons and see if the two distributions (or their means) are indeed separate. See the following examples. Also remember that we studied Atlantis temperature and the fact that variance changes maybe another way two distributions differ from one another. Have a look at the examples below to visualize how this can be achieved.\n",
    "\n",
    "![](img/dist1.png)\n",
    "\n",
    "![](img/climatedist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing in Statistics\n",
    "In summary, this will be our logic and workflow.\n",
    "\n",
    "1. We assume a null hypothesis and an alternative hypothesis.\n",
    "2. We calculate a statistic from data (maybe a sample mean, or something else) whose distribution we know if the null hypothesis is true\n",
    "3. If this statistic, based on its distribution, is very very unlikely we would think that the distribution is not true (i.e. the null hypothesis can be rejected)!\n",
    "4. If not, we fail to reject the null hypothesis\n",
    "\n",
    "Let's take an example of one such test. \n",
    "1. To compare the rabbit and tortoise speeds, we will first assume the null hypothesis that they both come from the same distribution (i.e. tortoises are as fast as rabbits).\n",
    "2. Now, if this null hypothesis were true, we can calculate that the sample mean of the speeds of tortoises should follow a normal distribution with mean = population mean of the rabbit speeds and some specific variance. Remember, given the mean and the variance for a normal distribution, we can exactly calculate the probability of different measurements.\n",
    "3. Now, we plug in the calculated sample mean of tortoise speeds into our distribution and see how likely are we to get such a sample mean for tortoises if the null hypothesis is actually true (i.e. they are as fast as rabbits). We will find that it is extremely unlikely we get such a result. So we assume that the null hypothesis is probably not true and reject it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Squared, A statistical test for categorical data\n",
    "\n",
    "Finally, we are ready to think about how to look at M&Ms. To do so we will use a statistical test, which is where all of our previous work was going. The Chi-Squared (χ²) test we will use is calculated as:\n",
    "\n",
    "$$\\chi^2 = \\frac{((\\text{number of actual observations} - \\text{number of expected observations})^2}{\\text{number of expected observations}}$$\n",
    "\n",
    "This χ² is the statistic now (like sample mean in the above example). We will calculate it from data and compare it with its distribution assuming the null hypothesis to get the idea how likely it is for us to get such a value if null hypothesis is actually true. If this is very unlikely, we reject the null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's assume in a classroom of 100 students, we expect to see 50 males and 50 females. How would we calculate the χ² value for a classroom where we saw 51 males and 49 females?\n",
    "\n",
    "Males:\n",
    "Observed number ($O$) = 51\n",
    "Expected number ($E$) = 50\n",
    "- $(O - E) = 1$\n",
    "- $(O - E)^2 = 1$\n",
    "- $\\frac{(O - E)^2}{E} = 0.02$\n",
    "\n",
    "So 0.02 is our χ² value. What does this mean? Nothing yet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know two more things. The first is easy, we need to know how many choices we could have had - in our classroom, how many possible catagories did we choose from? In our case, only two: Male or Female. We take our number of choices (n), and always subtract 1, to give us `df`, our 'degrees of freedom'. Now we can take the 0.02 value to the Chi-squared [chart](https://people.richland.edu/james/lecture/m170/tbl-chi.html). According to this chart with df = 1, the 0.02 value lies somewhere between 0.9 and 0.1. This is the probability to get such a value if the null hypothesis was true. It is very likely (0.9 means 90% chance!). Therefore, we do not reject the null hypothesis. If you look at the values, you can perhaps guess this. The null hypothesis (as many males as females in the class) is not violated by obvserving 2 more males than females! That can easily happen by chance. We will talk more about this later, but let's try an example with our M&Ms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M&Ms and Chi-Squared\n",
    "\n",
    "According to published information, here are the probabilities for M&M colors:\n",
    "\n",
    "|Color|Probability|\n",
    "|-----|-----------|\n",
    "|Blue|0.24|\n",
    "|Brown|0.13|\n",
    "|Green|0.16|\n",
    "|Yellow|0.14|\n",
    "|Red|0.13|\n",
    "|Orange|0.20|\n",
    "\n",
    "#### What is our null hypothesis? What is our alternative?\n",
    "Take a guess below. Are the M&Ms you have in your tube the same as any random sample of M&Ms? (i.e. are they a representative sample)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above, the complete the following python code by taking your counts of the M&Ms and placing them in code block below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary to hold the observations\n",
    "observed_mnm = {'Brown': ,\n",
    "                'Blue': ,\n",
    "                'Red': ,\n",
    "                'Orange': ,\n",
    "                'Yellow': ,\n",
    "                'Green': }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code block, we used a new data structure called dictionary. A dictionary works like a list in many ways, except you can call dictionary items by their name, rather than an index number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_favs = {'color':'red',\n",
    "           'day':'monday',\n",
    "          'fruit':'bannana'}\n",
    "\n",
    "print(my_favs['color'])\n",
    "print(type(my_favs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some special python functions\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['Blue', 'Brown', 'Green', 'Yellow', 'Red', 'Orange']\n",
    "# compute the total number of M&Ms\n",
    "total_mnm = 0\n",
    "for color in colors:\n",
    "    # get the color value from the observed_mnm dict\n",
    "    # add it to total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to do hypothesis testing, we need the \"expected\" frequencies\n",
    "# i.e. given the null hypotheses how many mnms of each color would we expect to get\n",
    "# we create another dictionary and assign to each color the probability under expected hypothesis (see above)\n",
    "# complete the dictionary below\n",
    "expected_probabilities = {\n",
    "    'Blue': ,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an expected percentages for each of the colors in order\n",
    "expected_values = []\n",
    "observed_values = []\n",
    "# we will use list.append to slowly build these lists one color at a time\n",
    "# the order in the two lists will be similar\n",
    "for color in colors:\n",
    "    observed_values.append(observed_mnm[color])  # add it to the observed list\n",
    "    expected_value_for_this_color = expected_probabilities[color] * total_mnm\n",
    "    # now append this value in the appropriate list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stats package will do the actual test for us. It will return both the statistic (the $\\chi^2$ statistic which we will compare to a known distribution) and something called a p-value (which is the probability that we would make similar observations if the null hypothesis is true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the stats package to do the ChiSquare test\n",
    "result = st.chisquare(observed_values, expected_values)\n",
    "print(f\"Chi-squared statistic is {result[0]}\")\n",
    "print(f\"p-value is: {result[1]}\")\n",
    "print(f\"Probability null hypothesis is true: {result[1] * 100}\")\n",
    "\n",
    "\n",
    "if (result[1] * 100) > 5:  # it is likely to get such a result by chance if null is true\n",
    "    print(\"You should accept the null hypthothesis!\")\n",
    "else:  # very unlikely to get such a result by chance if null is true, so we reject the null\n",
    "    print(\"You should reject the null hypthothesis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the plot to visually compare expected and observed probabilities\n",
    "\n",
    "from matplotlib.pyplot as plt\n",
    "\n",
    "data = \n",
    "# plot it using the plt.bar function we learnt about earlier\n",
    "plt.show()\n",
    "data2 = \n",
    "# plot it using the plt.bar function we learnt about earlier\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How testing allows us to evaluate a hypothesis\n",
    "![](img/pval1.png)\n",
    "![](img/rejecth0.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
