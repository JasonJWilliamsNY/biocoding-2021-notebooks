{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Principle 4 - The Normal Distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the cautionary tales! They reminded us to not just represent a sample/data in terms of summary statistics but use the whole distribution. So now, we study one such special distribution that often arises in real world data.\n",
    "\n",
    "As it turns out, when we make observations about our data (counting M&M colors, measuring rabbit speeds, taking blood pressure reading) we often come across something called the [Normal Distribution](https://en.wikipedia.org/wiki/Normal_distribution) also called the \"Gaussian distribution\". There is a lot of jargon, but put very simply, the normal distribution tells us that most of our samples should be about average (that's what average means anyway!). The idea is that most things of the same type (students in the same school/grade, cars being made at a factory, etc.) should have lots of similarities. Sometimes (in the case of cars) the individual members of a population should be nearly identical - it would not be good business if a every 5th car assembled was weirdly different from the rest. Here we say that we want to minimize the variance of the population (recall that variance tells us how much of the spread is there around the mean value in our data). On the other hand, if we take some data about human interests, we want it to have high variance (we do not want everyone just being interested in Math, no matter how interesting it is!). \n",
    "\n",
    "For an interesting cognitive fallacy, have a look here: [Lake Woebegon effect](https://en.wikipedia.org/wiki/Illusory_superiority)!\n",
    "\n",
    "One interesting feature about the normal distribution is that if we know the mean and the variance of the distribution, we can exactly calculate the distribution and the probabilities of different values! This is great, because in order to figure out the full distribution, we just need the mean and the variance (as long as the distribution really is a normal distribution).\n",
    "\n",
    "This is how a normal distribution looks like. It tells you how likely different values (plotted on the x axis are). You can see that most values are around the mean.\n",
    "\n",
    "![](img/normal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Challenge - calculating the variance\n",
    "\n",
    "Let us take another dataset for a change. Let us say we have data (fictitious) on temperatures in Atlantis in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "atlantis_temperature_2019 = [74, 70, 68, 66, 65, 70, 68, 66, 65, 68, 70, 69, 71, 74, 68, 70, 71, 72, 70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you estimate the spread around the mean? Since we use the terms \"around the mean\", we might assume that first of all we need to calculate, for each data point in our sample, how it lies in comparison to the mean. That is, if $\\mu$ is the mean and $X$ is the data point, we need to calculate $X - \\mu$ for each data point. This is called the deviation from the mean. \n",
    "\n",
    "\n",
    "But wait, this can be either positive or negative depending on the value $X$. To calculate the spread, we do not care whether we are above the mean or below. For example, if mean is 5, then both 6 and 4 are equal distance away from the mean and we will consider them to have the same \"spread\". Therefore we will calculate the square of the deviation from the mean $(X - \\mu)^2$. This way, both 4 and 6 give us the same value.\n",
    "\n",
    "Now we have one value of the squared devation from the mean for each data point. How do we get to the variance? Variance is simply the average squared deviation from the mean, i.e. we average (take the mean of) these squared deviations from the mean. How do we take the average? Sum them up and divide by their number! $\\sum (X - \\mu)^2 / N$. For weird statistical reasons, we sometimes keep $N - 1$ in the denominator but the idea is the same. See [here](https://en.wikipedia.org/wiki/Bessel's_correction) for more details.\n",
    "\n",
    "Finally, we define Standard Deviation as the square root of the variance. Why? If we are calculating the height in meters, then X and $\\mu$ have the units of meters, but variance has the units of meter squared. It is easier to understand the spread in the same units, so we take a square root and now the standard deviation has the same units as that of our original measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let us first get the mean and the total number of observations\n",
    "number_atlantis_temperature_2019 = len(atlantis_temperature_2019)\n",
    "mean_atlantis_temperature_2019 = np.mean(atlantis_temperature_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to move on to calculate the squared mean deviations. We will use a for loop for this\n",
    "total_squared_deviation_from_mean = 0\n",
    "for temp in atlantis_temperature_2019:\n",
    "    squared_deviation_from_mean = (temp - mean_atlantis_temperature_2019) ** 2\n",
    "    total_squared_deviation_from_mean += squared_deviation_from_mean\n",
    "variance_atlantis_temperature_2019 = total_squared_deviation_from_mean / (number_atlantis_temperature_2019 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there any easier way to do this using numpy? Yes!\n",
    "variance_numpy_version = np.var(atlantis_temperature_2019, ddof=1)  # ddof uses the N-1 version instead of N\n",
    "print(\"My variance: \" + str(variance_atlantis_temperature_2019))\n",
    "print(\"Numpy version: \" + str(variance_numpy_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we go to standard deviation\n",
    "sd_atlantis_temperature_2019 = np.sqrt(variance_atlantis_temperature_2019)\n",
    "# there is also a numpy function to do the same called np.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us look at what we can do with the spread. Let us say I have data about the temperatures in Atlantis in 2024. let us calculate its mean and sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantis_temperature_2024 = [74, 75, 60, 66, 65, 70, 68, 66, 65, 63, 70, 63, 77, 74, 68, 70, 71, 72, 78]\n",
    "mean_atlantis_temperature_2024 = np.mean(atlantis_temperature_2024)\n",
    "sd_atlantis_temperature_2024 = np.std(atlantis_temperature_2024, ddof=1)\n",
    "print(mean_atlantis_temperature_2019, mean_atlantis_temperature_2024)\n",
    "print(sd_atlantis_temperature_2019, sd_atlantis_temperature_2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we see? The mean is the same but the spread (SD) has almost doubled! This tells us about the weird kind of climate change occuring in Atlantis where there are more very hot and very cold days but the average temperatures are the same! (The real world climate change is causing both an increase in the mean temperature and the fluctuations or the spread)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
